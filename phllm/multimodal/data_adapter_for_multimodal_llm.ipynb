{
  "cells": [
    {
      "metadata": {
        "id": "ZrwVQsM9TiUw"
      },
      "cell_type": "markdown",
      "source": [
        "##### Copyright 2025 Google LLC.\n",
        "Licensed under the Apache 2.0 License."
      ]
    },
    {
      "metadata": {
        "id": "CpDUTVKYTowI"
      },
      "cell_type": "code",
      "source": [
        "# @title Licensed under the Apache 2.0 License (the \"License\"); { display-mode: \"form\" }\n",
        "# Copyright 2025 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "yZTdYJQDyZzy"
      },
      "cell_type": "markdown",
      "source": [
        "# Implementation of a data adapter for multimodal LLM input\n",
        "\n",
        "One way to train an LLM to use non-text data is to feed that data into the LLM's\n",
        "context window via an adapter. When you input natural language text into an LLM,\n",
        "it first gets transformed into tokens and then token embeddings. Each token\n",
        "embedding is a one-dimensional tensor of size D. This results in an input of K\n",
        "tokens mapping to a K by D matrix of inputs to the transfomer part of the LLM.\n",
        "\n",
        "Given this, a simple way to inject non-text data into the input stream of the\n",
        "LLM is to use an adapter to map the non-text data into a set of vectors of size\n",
        "D, which represent virtual tokens. For example, let's say we have a matrix\n",
        "dataset of dimension 10 by 100 that represents some features relevant to a\n",
        "single input to the LLM (a single sample). We feed the 10x100 matrix into an\n",
        "adapter that maps it into a T by D matrix, where T is some number of virtual\n",
        "tokens. Then we simply prepend this to our input matrix yielding a (K+T) by D\n",
        "matrix, which is input to the LLM.\n",
        "\n",
        "For training and evaluation of PROs in the PH-LLM paper, each input sample had a\n",
        "data input of size 40, which represents the concatenation of 20 mean values and\n",
        "20 variance values for 20 sensors. In this case, we learned an MLP adapter\n",
        "(implemented below) that maps the 1D tensor of length 40 to a 10 by 128\n",
        "dimensional matrix of virtual token embeddings. We then concatenated the virtual\n",
        "token matrix to the input matrix for the LLM.\n",
        "\n",
        "Here we provide a simple implementation of an adapter layer in flax that could\n",
        "be used to generate the virtual tokens."
      ]
    },
    {
      "metadata": {
        "id": "WkrGolzR1Vde"
      },
      "cell_type": "markdown",
      "source": [
        "## Install relevant packages"
      ]
    },
    {
      "metadata": {
        "id": "_SAYzENwyQ5F"
      },
      "cell_type": "code",
      "source": [
        "!pip install numpy\n",
        "!pip install flax\n",
        "!pip install jax"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "mZGC059108L7"
      },
      "cell_type": "code",
      "source": [
        "from flax import linen as nn\n",
        "import jax\n",
        "from jax import numpy as jnp\n",
        "import numpy as np"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "i7iukggk3iRk"
      },
      "cell_type": "markdown",
      "source": [
        "## Define Constants"
      ]
    },
    {
      "metadata": {
        "id": "2vnMFT6E1AjD"
      },
      "cell_type": "code",
      "source": [
        "# Size of the token embeddings used in the LLM transformer.\n",
        "MODEL_DIM = 128\n",
        "\n",
        "# Dimension of the input data to the adapter.\n",
        "DATA_INPUT_DIM = 40\n",
        "\n",
        "# Number of virtual tokens to use in the adapter.\n",
        "NUM_VIRTUAL_TOKENS = 10\n",
        "\n",
        "# Number of MLP layers to use in the data adapter.\n",
        "NUM_MLP_LAYERS = 5\n",
        "\n",
        "# MLP hidden dimension.\n",
        "MLP_HIDDEN_DIMS = 128\n",
        "\n",
        "# Batch size used in training.\n",
        "BATCH_SIZE = 8\n",
        "\n",
        "# Random seed\n",
        "RANDOM_SEED = 123"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "k__ZJxUL1DJt"
      },
      "cell_type": "code",
      "source": [
        "class SimpleAdapter(nn.Module):\n",
        "  \"\"\"A simple adapter layer for vector input data.\"\"\"\n",
        "\n",
        "  # The dimension of input data.\n",
        "  input_dims: int = 1\n",
        "  # The dimension of hidden layers.\n",
        "  hidden_dims: int = 128\n",
        "  # The dimension of the token embeddings.\n",
        "  token_embedding_dim: int = 128\n",
        "  # The number of virtual tokens to allocate to data encoding.\n",
        "  num_virtual_tokens: int = 10\n",
        "  # Number of layers for the MLP used in the adapter.\n",
        "  num_layers: int = 5\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, input: jnp.ndarray):\n",
        "    batch_size, _ = input.shape\n",
        "    x = input\n",
        "    # All but the last layer will have activation.\n",
        "    for i in range(self.num_layers - 1):\n",
        "      x = nn.Dense(features=self.input_dims)(x)\n",
        "      x = nn.relu(x)\n",
        "    # The final layer maps to the desired output dimension.\n",
        "    x = nn.Dense(features=self.token_embedding_dim * self.num_virtual_tokens)(x)\n",
        "    return jnp.reshape(\n",
        "        x, [batch_size, self.num_virtual_tokens, self.token_embedding_dim]\n",
        "    )"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "6MMm_lfp34Fo"
      },
      "cell_type": "markdown",
      "source": [
        "## Test the layer with synthetic data."
      ]
    },
    {
      "metadata": {
        "id": "XS6GnRW11IxP"
      },
      "cell_type": "code",
      "source": [
        "g_adapter_layer = SimpleAdapter(\n",
        "    name='adapter_config',\n",
        "    input_dims=DATA_INPUT_DIM,\n",
        "    hidden_dims=MLP_HIDDEN_DIMS,\n",
        "    token_embedding_dim=MODEL_DIM,\n",
        "    num_virtual_tokens=NUM_VIRTUAL_TOKENS,\n",
        "    num_layers=NUM_MLP_LAYERS,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "-VIjUz0M1LCD"
      },
      "cell_type": "code",
      "source": [
        "# We create an input matrix of size BATCH_SIZE by DATA_INPUT_DIM.\n",
        "# For example, with the default constants this represents\n",
        "# a matrix of 8 samples where each has a data input vector of size 40.\n",
        "_inputs_np = np.random.normal(\n",
        "    size=(\n",
        "        BATCH_SIZE,\n",
        "        DATA_INPUT_DIM,\n",
        "    )\n",
        ")\n",
        "_inputs = jnp.asarray(_inputs_np)\n",
        "\n",
        "print(f'We expect {BATCH_SIZE} samples by {DATA_INPUT_DIM}')\n",
        "print(f'_inputs: {_inputs.shape}')\n",
        "print('')\n",
        "\n",
        "\n",
        "_prng_key = jax.random.PRNGKey(seed=RANDOM_SEED)\n",
        "_initial_vars = g_adapter_layer.init({'params': _prng_key}, _inputs)\n",
        "_outputs = g_adapter_layer.apply(\n",
        "    {'params': _initial_vars['params']}, _inputs\n",
        ")\n",
        "\n",
        "\n",
        "# After pushing the input matrix through the adapter we expect that\n",
        "# the output of the adapter should be BATCH_SIZE by NUM_VIRTUAL_TOKENS\n",
        "# by MODEL_DIM or the token embedding size.\n",
        "print(\n",
        "    f'We expect {BATCH_SIZE} samples by {NUM_VIRTUAL_TOKENS} tokens by'\n",
        "    f' {MODEL_DIM} dim.'\n",
        ")\n",
        "print(f'_outputs: {_outputs.shape}')"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "jledM68D4f_Z"
      },
      "cell_type": "markdown",
      "source": [
        "## Where to go next\n",
        "\n",
        "The output of the adapter layer can be concatenated with the input to the LLMs.\n",
        "The details of how this is done will depend on the specific implementation."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
